{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/tensorflow/tensorrt/blob/r2.0/tftrt/examples/image-classification/TFv2-TF-TRT-inference-from-Keras-saved-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Copyright 2019 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dR1W9kv7IPhE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TF-TRT Inference from Keras Model with TensorFlow 2.0\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This example demonstrates the optimization of a Keras model using Nvidia's TensorRT library via TensorFlow integration with TensorRT (TF-TRT).  TF-TRT optimizes and executes compatible subgraphs, allowing TensorFlow to execute the remaining graph. While you can still use TensorFlow's wide and flexible feature set, TensorRT will parse the model and apply optimizations to the portions of the graph wherever possible.\n",
    "\n",
    "In this notebook, we demonstrate the process of creating a TF-TRT optimized model from a ResNet-50 Keras saved model and demonstrate the performance of models optimized using FP32, FP16, and INT8 precision.\n",
    "\n",
    "This demo designed to work with the Xavier NX.\n",
    "\n",
    "Note, during the running of this notebook, the kernel will be restarted serveral times to free up memory. This is done via the command:\n",
    "```\n",
    "os.kill(os.getpid(), 9)\n",
    "```"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "Yb3TdMZAkVNq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def check_tensor_core_gpu_present():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    for line in local_device_protos:\n",
    "        if \"compute capability\" in str(line):\n",
    "            compute_capability = float(line.physical_device_desc.split(\"compute capability: \")[-1])\n",
    "            if compute_capability>=7.0:\n",
    "                return True\n",
    "\n",
    "            \n",
    "print(\"Tensorflow version: \", tf.version.VERSION)\n",
    "print(\"Tensor Core GPU Present:\", check_tensor_core_gpu_present())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data\n",
    "\n",
    "We download several random images for testing from the Internet."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "v-R2iN4akVOi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!mkdir ./data\n",
    "!wget  -O ./data/img0.JPG \"https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/siberian-husky-detail.jpg?bust=1535566590&width=630\"\n",
    "!wget  -O ./data/img1.JPG \"https://www.hakaimagazine.com/wp-content/uploads/header-gulf-birds.jpg\"\n",
    "!wget  -O ./data/img2.JPG \"https://www.artis.nl/media/filer_public_thumbnails/filer_public/00/f1/00f1b6db-fbed-4fef-9ab0-84e944ff11f8/chimpansee_amber_r_1920x1080.jpg__1920x1080_q85_subject_location-923%2C365_subsampling-2.jpg\"\n",
    "!wget  -O ./data/img3.JPG \"https://www.familyhandyman.com/wp-content/uploads/2018/09/How-to-Avoid-Snakes-Slithering-Up-Your-Toilet-shutterstock_780480850.jpg\""
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVJ2-8rokVOl",
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "nWYufTjPCMgW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yyzwxjlm37jx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i in range(4):\n",
    "  img_path = './data/img%d.JPG'%i\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  plt.subplot(2,2,i+1)\n",
    "  plt.imshow(img);\n",
    "  plt.axis('off');"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "F_9n-AR1kVOv",
    "outputId": "e0ead6dc-e761-404e-a030-f6d3057a57da"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "\n",
    "We next download and test a ResNet-50 pre-trained model from the Keras model zoo and demonstrate that it is able to classifly our images."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "xeV4r2YTkVO1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = ResNet50(weights='imagenet')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "WwRBOikEkVO3",
    "outputId": "2d63bc46-8bac-492f-b519-9ae5f19176bc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(4):\n",
    "  img_path = './data/img%d.JPG'%i\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "\n",
    "  preds = model.predict(x)\n",
    "  # decode the results into a list of tuples (class, description, probability)\n",
    "  # (one such list for each sample in the batch)\n",
    "  print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "\n",
    "  plt.subplot(2,2,i+1)\n",
    "  plt.imshow(img);\n",
    "  plt.axis('off');\n",
    "  plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "lFKQPoLO_ikd",
    "outputId": "c0b93de8-c94b-4977-992e-c780e12a3d52"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF-TRT takes input as a TensorFlow saved model, therefore, we re-export the Keras model as a TF saved model."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "XrL3FEcdkVPA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "model.save('resnet50_saved_model') "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "WxlUF3rlkVPH",
    "outputId": "9f3864e7-f211-4c06-d2d2-585c1a477e34"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference with native TF2.0 saved model"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "qBQwBvlNm-J8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = tf.keras.models.load_model('resnet50_saved_model')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zLN0GMCkVPe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_path = './data/img0.JPG'  # Siberian_husky\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img);\n",
    "plt.axis('off');\n",
    "plt.title(decode_predictions(preds, top=3)[0][0][1])"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "Fbj-UEOxkVPs",
    "outputId": "3a2b34f9-8034-48cb-b3fe-477f09966025"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 8\n",
    "batched_input = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "for i in range(batch_size):\n",
    "  img_path = './data/img%d.JPG' % (i % 4)\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  batched_input[i, :] = x\n",
    "batched_input = tf.constant(batched_input)\n",
    "print('batched_input shape: ', batched_input.shape)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CGc-dC6DvwRP",
    "outputId": "e0a22e05-f4fe-47b6-93e8-2b806bf7098a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Benchmarking throughput\n",
    "N_warmup_run = 50\n",
    "N_run = 1000\n",
    "elapsed_time = []\n",
    "\n",
    "for i in range(N_warmup_run):\n",
    "  preds = model.predict(batched_input)\n",
    "\n",
    "for i in range(N_run):\n",
    "  start_time = time.time()\n",
    "  preds = model.predict(batched_input)\n",
    "  end_time = time.time()\n",
    "  elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "  if i % 50 == 0:\n",
    "    print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFBV6hQR7N3z"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's reset to clean up our memory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-TRT FP32 model\n",
    "\n",
    "We first convert the TF native FP32 model to a TF-TRT FP32 model."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "vC_RN0BAkVPy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Converting to TF-TRT FP32...')\n",
    "\n",
    "# max_workspace_size_bytes sets how much GPU memory will be avaible at runtime\n",
    "# what happens if you make max value bigger (say 8000000000) or smaller (say 1000000000)?\n",
    "max = 3000000000\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt.TrtPrecisionMode.FP32,\n",
    "                                                               max_workspace_size_bytes=max)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir='resnet50_saved_model',\n",
    "                                    conversion_params=conversion_params)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='resnet50_saved_model_TFTRT_FP32')\n",
    "print('Done Converting to TF-TRT FP32')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "0eLImSJ-kVPz",
    "outputId": "e2c353c7-8e4b-49aa-ab97-f4d82797d4d8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we load and test the TF-TRT FP32 model."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "Vd2DoGUp8ivj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 8\n",
    "batched_input = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "for i in range(batch_size):\n",
    "  img_path = './data/img%d.JPG' % (i % 4)\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  batched_input[i, :] = x\n",
    "batched_input = tf.constant(batched_input)\n",
    "print('batched_input shape: ', batched_input.shape)\n",
    "\n",
    "def predict_tftrt(saved_model_loaded):\n",
    "    \"\"\"Runs prediction on a single image and shows the result.\n",
    "    input_saved_model (string): Name of the input model stored in the current dir\n",
    "    \"\"\"\n",
    "    \n",
    "    signature_keys = list(saved_model_loaded.signatures.keys())\n",
    "    print(signature_keys)\n",
    "\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "    print(infer.structured_outputs)\n",
    "\n",
    "\n",
    "    for i in range(4):\n",
    "      img_path = './data/img%d.JPG'%i\n",
    "      #img_path = './data/img0.JPG'  # Siberian_husky\n",
    "      img = image.load_img(img_path, target_size=(224, 224))\n",
    "      x = image.img_to_array(img)\n",
    "      x = np.expand_dims(x, axis=0)\n",
    "      x = preprocess_input(x)\n",
    "      x = tf.constant(x)\n",
    "    \n",
    "      labeling = infer(x)\n",
    "      preds = labeling['predictions'].numpy()\n",
    "      print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "      plt.subplot(2,2,i+1)\n",
    "      plt.imshow(img);\n",
    "      plt.axis('off');\n",
    "      plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "    \n",
    "def benchmark_tftrt(saved_model_loaded):\n",
    "    # saved_model_loaded = tf.saved_model.load(input_saved_model, tags=[tag_constants.SERVING])\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "    N_warmup_run = 50\n",
    "    N_run = 1000\n",
    "    elapsed_time = []\n",
    "\n",
    "    for i in range(N_warmup_run):\n",
    "      labeling = infer(batched_input)\n",
    "\n",
    "    for i in range(N_run):\n",
    "      start_time = time.time()\n",
    "      labeling = infer(batched_input)\n",
    "      end_time = time.time()\n",
    "      elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "      if i % 50 == 0:\n",
    "        print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "    print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rf97K_rxvwRm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## load the model\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load('resnet50_saved_model_TFTRT_FP32', tags=[tag_constants.SERVING])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_tftrt(saved_model_loaded)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "pRK0pRE-snvb",
    "outputId": "1f7ab6c1-dbfa-4e3e-a21d-df9975c70455"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "benchmark_tftrt(saved_model_loaded)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai6bxNcNszHc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-TRT FP16 model\n",
    "We next convert the native TF FP32 saved model to TF-TRT FP16 model."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "G2F8t6cPkVQS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Converting to TF-TRT FP16...')\n",
    "\n",
    "# max_workspace_size_bytes sets how much GPU memory will be avaible at runtime\n",
    "# what happens if you make max value bigger (say 8000000000) or smaller (say 1000000000)?\n",
    "max = 3000000000\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "    precision_mode=trt.TrtPrecisionMode.FP16,\n",
    "    max_workspace_size_bytes=max)\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "   input_saved_model_dir='resnet50_saved_model', conversion_params=conversion_params)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='resnet50_saved_model_TFTRT_FP16')\n",
    "print('Done Converting to TF-TRT FP16')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "0ia_AlSDkVQT",
    "outputId": "d29eb6de-101b-4b9a-8ebf-4880a2e469bf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 8\n",
    "batched_input = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "for i in range(batch_size):\n",
    "  img_path = './data/img%d.JPG' % (i % 4)\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  batched_input[i, :] = x\n",
    "batched_input = tf.constant(batched_input)\n",
    "print('batched_input shape: ', batched_input.shape)\n",
    "\n",
    "def predict_tftrt(saved_model_loaded):\n",
    "    \"\"\"Runs prediction on a single image and shows the result.\n",
    "    input_saved_model (string): Name of the input model stored in the current dir\n",
    "    \"\"\"\n",
    "    \n",
    "    signature_keys = list(saved_model_loaded.signatures.keys())\n",
    "    print(signature_keys)\n",
    "\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "    print(infer.structured_outputs)\n",
    "\n",
    "\n",
    "    for i in range(4):\n",
    "      img_path = './data/img%d.JPG'%i\n",
    "      #img_path = './data/img0.JPG'  # Siberian_husky\n",
    "      img = image.load_img(img_path, target_size=(224, 224))\n",
    "      x = image.img_to_array(img)\n",
    "      x = np.expand_dims(x, axis=0)\n",
    "      x = preprocess_input(x)\n",
    "      x = tf.constant(x)\n",
    "    \n",
    "      labeling = infer(x)\n",
    "      preds = labeling['predictions'].numpy()\n",
    "      print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "      plt.subplot(2,2,i+1)\n",
    "      plt.imshow(img);\n",
    "      plt.axis('off');\n",
    "      plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "    \n",
    "def benchmark_tftrt(saved_model_loaded):\n",
    "    # saved_model_loaded = tf.saved_model.load(input_saved_model, tags=[tag_constants.SERVING])\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "    N_warmup_run = 50\n",
    "    N_run = 1000\n",
    "    elapsed_time = []\n",
    "\n",
    "    for i in range(N_warmup_run):\n",
    "      labeling = infer(batched_input)\n",
    "\n",
    "    for i in range(N_run):\n",
    "      start_time = time.time()\n",
    "      labeling = infer(batched_input)\n",
    "      end_time = time.time()\n",
    "      elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "      if i % 50 == 0:\n",
    "        print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "    print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## load the model\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load('resnet50_saved_model_TFTRT_FP16', tags=[tag_constants.SERVING])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_tftrt(saved_model_loaded)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "yTDbB6DWn0kJ",
    "outputId": "33cd23f8-9c8b-4cdd-9c7a-4939aae12f56"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "benchmark_tftrt(saved_model_loaded)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_gerN5j9l6U"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRXVurzh6o5T"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-TRT INT8 model\n",
    "\n",
    "Int8 is not supported on the Jetson Nano."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "qKSJ-oizkVQY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "In this notebook, we have demonstrated the process of creating TF-TRT FP32, and FP16 inference models from an original Keras FP32 model, as well as verify their speed and accuracy. \n",
    "\n",
    "### What's next\n",
    "Try changing the batch size for the input and the max_workspace_size_bytes to see if you can get better (or worse) performance.  What happens if you change the NX's power modes?\n",
    "\n",
    "Try TF-TRT on your own model and data, and experience the simplicity and speed up it offers."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "I13snJ9VkVQh"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Colab-TF20-TF-TRT-inference-from-Keras-saved-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}